# 测试:alpha（α）、beta（β）和gamma（γ）;发布:released
dev.versions: released
# 拓扑配置
topology.name: captureAtomEvent-SDC
topology.workers: 1
topology.message.timeout.secs: 1500
topology.acker.executors: 0
topology.max.spout.pending: 20
source.data.id: 1001
source.data.fileds: START_TIME,IMSI,IMEI,EVENT_TYPE,DURATION,START_LAC,START_CI,END_LAC,END_CI,SOUR_LAC,SOUR_CI,DEST_LAC,DEST_CI,CAUSE,HLR,VLR,MSISDN,OPPO_NUM,OTHER_NUM,RES2,SPLITCHAR
source.data.dynamic.args.fileds: START_TIME,IMSI,IMEI,DURATION,START_LAC,START_CI,END_LAC,END_CI,SOUR_LAC,SOUR_CI,DEST_LAC,DEST_CI,OPPO_NUM
join.msisdn.by.imsi.bolt.parallelism.hint: 3
join.msisdn.by.imsi.bolt.store.tablename: "XJAE:CIM:"
# kafka配置
kafka.topic: SDC_DATA
kafka.spoutid: captureAtomEvent-SDC
zookeeper.root: "/storm"
kafka.brokerlist: "192.168.1.54:9092,192.168.1.55:9092,192.168.1.56:9092,192.168.1.57:9092,192.168.1.58:9092,192.168.1.59:9092,192.168.1.60:9092,192.168.1.61:9092"
kafka.zklist: "192.168.1.55:2181,192.168.1.56:2181,192.168.1.57:2181,192.168.1.58:2181,192.168.1.59:2181,192.168.1.60:2181,192.168.1.61:2181"
force.from.begin: true
zookeeper.servers:
     - "192.168.1.55"
     - "192.168.1.56"
     - "192.168.1.57"
     - "192.168.1.58"
     - "192.168.1.59"
     - "192.168.1.60"
     - "192.168.1.61"
# gbase配置
gbase.db.name: bigdata
gbase.db.driver: "com.gbase.jdbc.Driver"
gbase.db.url: "jdbc:gbase://10.238.156.1:5258/bigdata"
gbase.db.username: gbase
gbase.db.password: gbase20110531
# Redis 配置
redis.cluster.nodes.size: 9
redis.cluster.nodes.hostandport:
     - "192.168.1.54:7001"
     - "192.168.1.54:7002"
     - "192.168.1.54:7003"
     - "192.168.1.55:7004"
     - "192.168.1.55:7005"
     - "192.168.1.55:7006"
     - "192.168.1.56:7007"
     - "192.168.1.56:7008"
     - "192.168.1.56:7009"
redis.cluster.connect.timeout: 15000
redis.cluster.connect.max_redirections: 100
# hdfs 配置
hdfs.hdfssite.file.path: "/home/stormdev/storm/conf/hdfs-site.xml"
hdfs.coresite.file.path: "/home/stormdev/storm/conf/core-site.xml"
fs.defaultFS: "hdfs://xjcluster"
dfs.nameservices: "xjcluster"
dfs.ha.namenodes: "nn1,nn2"
dfs.ha.namenodes.addr: "nn1:8020,nn2:8020"
dfs.ha.namenodes.size: 2
dfs.client.failover.proxy.provider: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"